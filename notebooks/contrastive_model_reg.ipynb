{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0c06aac-4dc9-42f7-a262-55b9f72ce538",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "import os\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import scanpy as sc \n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm  # Import tqdm\n",
    "import pickle \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torchmetrics import Accuracy\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "import torch.backends.cuda\n",
    "torch.backends.cuda.enable_flash_sdp(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "653be268-7fcf-4a40-9c03-3aac82dc21b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "12.1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "print(torch.version.cuda)\n",
    "print(torch.cuda.device_count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76e47fd2-c06f-4c84-9117-347eb5bc7d07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell data shape: (244659, 40)\n",
      "Using labels from SingleR.\n",
      "Cell data shape: (244659, 41)\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "# Select platform\n",
    "platform = \"xenium\" # xenium or visium \n",
    "ground_truth = \"refined\"  # refined or cellvit\n",
    "level = 0\n",
    "filtered_genes = False\n",
    "label_source = \"singleR\"  # singleR, celltypist, aistil, combined\n",
    "morph_version = \"v2\"\n",
    "use_qc = False\n",
    "limit_classes = True  # Set to False to use all classes\n",
    "\n",
    "\n",
    "if platform == \"xenium\":\n",
    "    cancer = \"lung\"\n",
    "    xenium_folder_dict = {\"lung\": \"Xenium_Prime_Human_Lung_Cancer_FFPE_outs\",\n",
    "                          \"breast\":\"Xenium_Prime_Breast_Cancer_FFPE_outs\",\n",
    "                          \"lymph_node\": \"Xenium_Prime_Human_Lymph_Node_Reactive_FFPE_outs\",\n",
    "                          \"prostate\": \"Xenium_Prime_Human_Prostate_FFPE_outs\",\n",
    "                          \"skin\": \"Xenium_Prime_Human_Skin_FFPE_outs\",\n",
    "                          \"ovarian\": \"Xenium_Prime_Ovarian_Cancer_FFPE_outs\",\n",
    "                          \"cervical\": \"Xenium_Prime_Cervical_Cancer_FFPE_outs\"\n",
    "                          }\n",
    "\n",
    "    xenium_folder = xenium_folder_dict[cancer]\n",
    "    celltypist_data_path = f\"/rsrch9/home/plm/idso_fa1_pathology/TIER1/paul-xenium/public_data/10x_genomics/{xenium_folder}/preprocessed/fine_tune_{ground_truth}_v2/processed_xenium_data_fine_tune_{ground_truth}_ImmuneHigh_v2.h5ad\"\n",
    "    singleR_data_path = f\"/rsrch9/home/plm/idso_fa1_pathology/TIER1/paul-xenium/public_data/10x_genomics/{xenium_folder}/preprocessed/fine_tune_{ground_truth}_v2/processed_xenium_data_fine_tune_{ground_truth}_v2_annotated.h5ad\"\n",
    "    \n",
    "    embedding_dir = f\"/rsrch9/home/plm/idso_fa1_pathology/TIER2/paul-xenium/embeddings/public_data/{xenium_folder}\"\n",
    "\n",
    "    gene_emb_path = f\"{embedding_dir}/scGPT/scGPT_CP.h5ad\"\n",
    "\n",
    "    # if filtered_genes:\n",
    "    #     gene_embedding_file = f\"/rsrch9/home/plm/idso_fa1_pathology/TIER2/paul-xenium/embeddings/public_data/{xenium_folder}/processed_xenium_refined_clustering_filtered_v2.csv\"\n",
    "    # else:\n",
    "    #     gene_embedding_file = f\"/rsrch9/home/plm/idso_fa1_pathology/TIER2/paul-xenium/embeddings/public_data/{xenium_folder}/processed_xenium_{ground_truth}_v2.csv\"\n",
    "    \n",
    "    # Load Morphological Embeddings\n",
    "\n",
    "        \n",
    "elif platform == \"visium\":\n",
    "    data_path = \"/rsrch9/home/plm/idso_fa1_pathology/TIER1/paul-xenium/public_data/10x_genomics/Visium_HD_Human_Lung_Cancer_post_Xenium_Prime_5k_Experiment2/binned_outputs/square_002um/preprocessed/bin2cell/to_tokenize/corrected_cells_matched_preprocessed_refined_v2.h5ad\"\n",
    "    singleR_data_path = \"/rsrch9/home/plm/idso_fa1_pathology/TIER1/paul-xenium/public_data/10x_genomics/Visium_HD_Human_Lung_Cancer_post_Xenium_Prime_5k_Experiment2/binned_outputs/square_002um/preprocessed/bin2cell/corrected_cells_matched_preprocessed_refined_v2_annotated.h5ad\"\n",
    "\n",
    "    # gene_embedding_file = \"/rsrch9/home/plm/idso_fa1_pathology/TIER2/paul-xenium/embeddings/public_data/Visium_HD_Human_Lung_Cancer_post_Xenium_Prime_5k_Experiment2/bin2cell/embeddings_output/processed_visium_hd_bin2cell.csv\"\n",
    "    embedding_dir = \"/rsrch9/home/plm/idso_fa1_pathology/TIER2/paul-xenium/embeddings/public_data/Visium_HD_Human_Lung_Cancer_post_Xenium_Prime_5k_Experiment2/\"\n",
    "    gene_emb_path = \"/rsrch9/home/plm/idso_fa1_pathology/TIER2/paul-xenium/embeddings/public_data/Visium_HD_Human_Lung_Cancer_post_Xenium_Prime_5k_Experiment2/b2c_scGPT_WH.h5ad\"\n",
    "\n",
    "\n",
    "# Load AnnData\n",
    "if label_source == \"singleR\":\n",
    "    data_path = singleR_data_path\n",
    "    adata = sc.read_h5ad(data_path)\n",
    "    \n",
    "    \n",
    "elif label_source == \"celltypist\":\n",
    "    data_path = celltypist_data_path\n",
    "    adata = sc.read_h5ad(data_path)\n",
    "    \n",
    "elif label_source == \"combined\":\n",
    "    adata = sc.read_h5ad(singleR_data_path)\n",
    "    bdata = sc.read_h5ad(celltypist_data_path)\n",
    "    adata.obs[\"majority_voting\"] = bdata.obs[\"majority_voting\"]\n",
    "    adata.obs[\"qc_celltypist\"] = bdata.obs[\"qc_celltypist\"]\n",
    "    cell_data = adata.obs\n",
    "\n",
    "cell_data = adata.obs\n",
    "print(\"Cell data shape:\", cell_data.shape)\n",
    "# Load Morphology Embeddings \n",
    "if morph_version == \"v1\":\n",
    "    morph_embedding_csv = os.path.join(embedding_dir, \"UNI2_cell_representation\",f\"level_{level}\",\"morphology_embeddings_v2.csv\")  \n",
    "else:\n",
    "    morph_embedding_csv = os.path.join(embedding_dir, \"UNI2_cell_representation\",f\"level_{level}\",\"uni2_pretrained_embeddings.csv\") \n",
    "\n",
    "morph_embeddings = pd.read_csv(morph_embedding_csv, index_col=\"Unnamed: 0\")\n",
    "\n",
    "# Load gene Embeddings \n",
    "# gene_embeddings = pd.read_csv(gene_embedding_file, index_col=\"Unnamed: 0\")\n",
    "gdata = sc.read_h5ad(gene_emb_path)\n",
    "\n",
    "\n",
    "if platform == \"visium\":\n",
    "    # Ensure index alignment\n",
    "    cell_data.index = cell_data.index.astype(str)\n",
    "    gdata.obs_names = gdata.obs_names.astype(str)\n",
    "    morph_embeddings.index = morph_embeddings.index.astype(str)\n",
    "    \n",
    "    # Filter cell_data to match gene embeddings\n",
    "    cell_data = cell_data.loc[gdata.obs_names]\n",
    "\n",
    "    # Align morphology embeddings to gene_embeddings (which should already be filtered)\n",
    "    morph_embeddings = morph_embeddings.loc[cell_data.index]\n",
    "\n",
    "\n",
    "# Now create gene_embeddings with matching index\n",
    "gene_embeddings = pd.DataFrame(gdata.obsm[\"X_scGPT\"], index=gdata.obs_names)\n",
    "\n",
    "assert (morph_embeddings.index == gene_embeddings.index).all(), \"Indices are not aligned!\"\n",
    "\n",
    "# Spatial Information \n",
    "spatial_coords = cell_data[['x_centroid', 'y_centroid']].rename(columns={'x_centroid': 'x', 'y_centroid': 'y'})\n",
    "\n",
    "\n",
    "if label_source==\"singleR\":\n",
    "    print(\"Using labels from SingleR.\")\n",
    "    singleR_to_class_map = {\n",
    "        \"Smooth muscle\": \"fibroblast\",\n",
    "        \"Fibroblasts\": \"fibroblast\",\n",
    "        \"Endothelial cells\": \"endothelial\",\n",
    "        \"CD4+ T-cells\": \"t_cell\",\n",
    "        \"CD8+ T-cells\": \"t_cell\",\n",
    "        \"B-cells\": \"b_cell\",\n",
    "        \"Macrophages\": \"macrophage\",\n",
    "        \"Epithelial cells\": \"epithelial\",\n",
    "    }\n",
    "    \n",
    "    target_classes = [\"fibroblast\", \"endothelial\",\n",
    "                      \"t_cell\", \"b_cell\", \"macrophage\",\n",
    "                      \"epithelial\"]\n",
    "    \n",
    "    # Map SingleR labels to 7-class system\n",
    "    cell_data[label_source] = cell_data[\"singleR_class\"].map(singleR_to_class_map)\n",
    "    \n",
    "    # Drop cells that are nan (if any)\n",
    "    # cell_data = cell_data.dropna(subset=[label_source])\n",
    "    \n",
    "    # Keep only those 7 classes\n",
    "    # cell_data = cell_data[cell_data[label_source].isin(target_classes)]\n",
    "    print(\"Cell data shape:\", cell_data.shape)\n",
    "\n",
    "    \n",
    "    if use_qc:\n",
    "        cell_data = cell_data[cell_data[\"qc_singleR\"]==1]\n",
    "\n",
    "    \n",
    "    # Reindex embeddings/coords\n",
    "    gene_embeddings = gene_embeddings.reindex(cell_data.index)\n",
    "    morph_embeddings = morph_embeddings.reindex(cell_data.index)\n",
    "    spatial_coords = spatial_coords.reindex(cell_data.index)\n",
    "    \n",
    "    \n",
    "elif label_source==\"aistil\":\n",
    "    print(\"Using AISTIL labels\")\n",
    "    label_source = \"class\"\n",
    "    target_classes = [\"f\", \"l\", \"t\"]  # Modify this list to restrict classification to specific classes\n",
    "    if limit_classes:\n",
    "        num_classes = len(target_classes)\n",
    "        cell_data = cell_data[cell_data[label_source].isin(target_classes)]\n",
    "\n",
    "        # Change index type for Visium data to match embeddings Idxs \n",
    "        if platform == \"visium\":\n",
    "            morph_embeddings.index = morph_embeddings.index.astype(str)\n",
    "\n",
    "        # Update corresponding embeddings and spatial coordinates\n",
    "        gene_embeddings = gene_embeddings.reindex(cell_data.index)\n",
    "        morph_embeddings = morph_embeddings.reindex(cell_data.index)\n",
    "        spatial_coords = spatial_coords.reindex(cell_data.index)\n",
    "    else:\n",
    "        target_classes = [\"f\",\"l\",\"o\",\"t\"]\n",
    "        \n",
    "elif label_source==\"celltypist\":\n",
    "    print(\"Using CellTypist Labels\")\n",
    "    celltypist_to_class_map = {\n",
    "        \"Fibroblasts\": \"fibroblast\",\n",
    "        \"Endothelial cells\": \"endothelial\",\n",
    "        \"T cells\": \"t_cell\",\n",
    "        \"B cells\": \"b_cell\",\n",
    "        \"Macrophages\": \"macrophage\",\n",
    "        \"Epithelial cells\": \"epithelial\",\n",
    "    }\n",
    "    target_classes = [\"fibroblast\", \"endothelial\",\n",
    "                      \"t_cell\", \"b_cell\", \"macrophage\",\n",
    "                      \"epithelial\"]\n",
    "\n",
    "    # Map SingleR labels to 7-class system\n",
    "    cell_data[label_source] = cell_data[\"majority_voting\"].map(celltypist_to_class_map)\n",
    "    \n",
    "    # Drop cells that are nan (if any)\n",
    "    # cell_data = cell_data.dropna(subset=[])\n",
    "    \n",
    "    # Keep only those 7 classes\n",
    "    # cell_data = cell_data[cell_data[label_source].isin(target_classes)]\n",
    "\n",
    "    if use_qc:\n",
    "        cell_data = cell_data[cell_data[\"qc_celltypist\"]==1]\n",
    "\n",
    "    # Reindex embeddings/coords\n",
    "    gene_embeddings = gene_embeddings.reindex(cell_data.index)\n",
    "    morph_embeddings = morph_embeddings.reindex(cell_data.index)\n",
    "    spatial_coords = spatial_coords.reindex(cell_data.index)\n",
    "    \n",
    "elif label_source == \"combined\":\n",
    "    print(\"Using combined SingleR and CellTypist labels (agreement only)\")\n",
    "\n",
    "    # Define the shared label map and target classes\n",
    "    shared_class_map = {\n",
    "        \"Fibroblasts\": \"fibroblast\",\n",
    "        \"Smooth muscle\": \"fibroblast\",\n",
    "        \"Endothelial cells\": \"endothelial\",\n",
    "        \"CD4+ T-cells\": \"t_cell\",\n",
    "        \"CD8+ T-cells\": \"t_cell\",\n",
    "        \"T cells\": \"t_cell\",\n",
    "        \"B cells\": \"b_cell\",\n",
    "        \"B-cells\": \"b_cell\",\n",
    "        \"Macrophages\": \"macrophage\",\n",
    "        \"Epithelial cells\": \"epithelial\",\n",
    "    }\n",
    "    \n",
    "    target_classes = [\"fibroblast\", \"endothelial\", \"t_cell\", \"b_cell\", \"macrophage\", \"epithelial\"]\n",
    "\n",
    "    # First map the labels (these are safe)\n",
    "    cell_data[\"singleR_mapped\"] = cell_data[\"singleR_class\"].map(shared_class_map)\n",
    "    cell_data[\"celltypist_mapped\"] = cell_data[\"majority_voting\"].map(shared_class_map)\n",
    "    \n",
    "    # Then immediately filter with a properly aligned mask\n",
    "    cell_data = cell_data[\n",
    "        cell_data[\"singleR_mapped\"].notnull() &\n",
    "        cell_data[\"celltypist_mapped\"].notnull() &\n",
    "        (cell_data[\"singleR_mapped\"] == cell_data[\"celltypist_mapped\"])\n",
    "    ].copy()\n",
    "    \n",
    "\n",
    "    # Rename the final label column\n",
    "    cell_data[\"combined\"] = cell_data[\"singleR_mapped\"]\n",
    "    \n",
    "    if use_qc:\n",
    "        qc_mask = cell_data[\"qc_singleR\"] == 1\n",
    "        if \"qc_celltypist\" in cell_data.columns:\n",
    "            qc_mask &= cell_data[\"qc_celltypist\"] == 1\n",
    "        cell_data = cell_data[qc_mask]\n",
    "\n",
    "    # Reindex everything to the filtered cells\n",
    "    gene_embeddings = gene_embeddings.reindex(cell_data.index)\n",
    "    morph_embeddings = morph_embeddings.reindex(cell_data.index)\n",
    "    spatial_coords = spatial_coords.reindex(cell_data.index)\n",
    "\n",
    "\n",
    "\n",
    "num_classes = len(target_classes)\n",
    "label_mapping = {cls_name: i for i, cls_name in enumerate(target_classes)}\n",
    "labels = pd.Series(cell_data[label_source].map(label_mapping))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63b630c2-0bbf-4ee0-ab8b-2bf4e68664a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU setup\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "225b80a2-23bb-4cc0-85cc-94d22c78c9c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([244659, 512])\n"
     ]
    }
   ],
   "source": [
    "# Convert dataframes to tensors\n",
    "gene_tensor = torch.tensor(gene_embeddings.values, dtype=torch.float32).to(device)\n",
    "morph_tensor = torch.tensor(morph_embeddings.values, dtype=torch.float32).to(device)\n",
    "print(gene_tensor.shape)\n",
    "# Confirm shapes match\n",
    "assert gene_tensor.shape[0] == morph_tensor.shape[0], \"Mismatch in cell counts.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "a8667241-206a-4987-ab8b-22a664378c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ───────────────────────── configuration ─────────────────────────\n",
    "proj_dim       = 256\n",
    "lr_peak        = 1e-4\n",
    "epochs         = 50\n",
    "batch_size     = 2048\n",
    "tau            = 0.15\n",
    "theta          = 0.20          # keep a low, fixed mask threshold\n",
    "warmup_epochs  = 5             # pure InfoNCE before blending\n",
    "alpha_end      = 0.20          # final weight of InfoNCE in the blend\n",
    "grad_clip      = 5.0\n",
    "device         = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "93bb9b35-3cdc-45c9-8e2e-de8d71a76847",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProjectionHead(nn.Module):\n",
    "    def __init__(self, in_dim, proj_dim=256, drop=0.3):\n",
    "        super().__init__()\n",
    "        self.proj  = nn.Linear(in_dim, proj_dim)\n",
    "        self.act   = nn.GELU()\n",
    "        self.fc    = nn.Linear(proj_dim, proj_dim)\n",
    "        self.drop  = nn.Dropout(drop)\n",
    "        self.norm  = nn.LayerNorm(proj_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.proj(x)\n",
    "        z = self.act(y)\n",
    "        z = self.fc(z)\n",
    "        z = self.drop(z)\n",
    "        z = z + y            # residual\n",
    "        return self.norm(z)\n",
    "\n",
    "\n",
    "# Initialize projection networks\n",
    "\n",
    "gene_proj_net = ProjectionHead(in_dim=gene_tensor.shape[1]).to(device)\n",
    "morph_proj_net = ProjectionHead(in_dim=morph_tensor.shape[1]).to(device)\n",
    "\n",
    "if weight_init:\n",
    "    def init_proj(net):\n",
    "        for m in net.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight, gain=weight_gain)  # bigger variance\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "    \n",
    "    gene_proj_net.apply(init_proj)\n",
    "    morph_proj_net.apply(init_proj)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "0f28b499-f252-4a0c-a649-3923b4625f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─────────────────────── loss functions ─────────────────────────\n",
    "def infoNCE(z_a, z_b, tau):\n",
    "    z_a, z_b = F.normalize(z_a, dim=1), F.normalize(z_b, dim=1)\n",
    "    logits   = z_a @ z_b.T / tau\n",
    "    labels   = torch.arange(z_a.size(0), device=z_a.device)\n",
    "    return 0.5 * (\n",
    "        F.cross_entropy(logits, labels) + F.cross_entropy(logits.T, labels)\n",
    "    )\n",
    "\n",
    "def masked_bleep(z_a, z_b, tau, theta):\n",
    "    z_a, z_b = F.normalize(z_a, dim=1), F.normalize(z_b, dim=1)\n",
    "    logits   = (z_a @ z_b.T) / tau\n",
    "    with torch.no_grad():\n",
    "        mask = ((z_a @ z_a.T) > theta) & ((z_b @ z_b.T) > theta)\n",
    "        mask.fill_diagonal_(True)\n",
    "        targets = mask.float()\n",
    "        targets /= targets.sum(1, keepdim=True)\n",
    "    log_q = F.log_softmax(logits, dim=-1)\n",
    "    loss  = -(targets * log_q ).sum(-1).mean()\n",
    "    loss += -(targets * log_q.T).sum(-1).mean()\n",
    "    return 0.5 * loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "8477e57c-ee95-496f-83d2-457da5272306",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ───────────────────── diagnostics helper (C) ───────────────────\n",
    "def quick_stats(z_g, z_m):\n",
    "    with torch.no_grad():\n",
    "        z_g, z_m = F.normalize(z_g, dim=1), F.normalize(z_m, dim=1)\n",
    "        pos = (z_g * z_m).sum(dim=1).mean().item()\n",
    "        neg = (z_g @ z_m.T).mean().item()\n",
    "    return pos, neg\n",
    "    \n",
    "def row_alignment_score(raw_a, raw_b):\n",
    "    \"\"\"\n",
    "    Quick test *before training*: 1.0 = perfectly aligned rows,\n",
    "    0.0 = completely random. If this is ~0 your tensors are scrambled.\n",
    "    \"\"\"\n",
    "    raw_a = F.normalize(raw_a, dim=1)\n",
    "    raw_b = F.normalize(raw_b, dim=1)\n",
    "    r1 = ((raw_a @ raw_b.T).argmax(dim=1) ==\n",
    "          torch.arange(raw_a.size(0), device=raw_a.device)).float().mean()\n",
    "    return r1.item()\n",
    "\n",
    "# ──────────────────────────────────────────────────────────\n",
    "#  Training loop with *inline* diagnostics\n",
    "# ──────────────────────────────────────────────────────────\n",
    "def train_bleep(gene, morph):\n",
    "    g_proj, m_proj = (ProjectionHead(gene.shape[1], proj_dim).to(device),\n",
    "                      ProjectionHead(morph.shape[1], proj_dim).to(device))\n",
    "    params  = list(g_proj.parameters()) + list(m_proj.parameters())\n",
    "    opt     = torch.optim.AdamW(params, lr=lr_peak, weight_decay=0.0)\n",
    "\n",
    "    N, idx = gene.size(0), np.arange(gene.size(0))\n",
    "    for ep in range(1, epochs + 1):\n",
    "        np.random.shuffle(idx); running = 0.0\n",
    "        # weight of InfoNCE in the blended loss (linear decay)\n",
    "        if ep <= warmup_epochs:\n",
    "            alpha = 1.0\n",
    "        else:\n",
    "            frac  = (ep - warmup_epochs) / (epochs - warmup_epochs)\n",
    "            alpha = max(1 - (1 - alpha_end) * frac, 0.60)   # ← keep ≥0.60\n",
    "        for s in range(0, N, batch_size):\n",
    "            b   = idx[s : s + batch_size]\n",
    "            z_g = g_proj(gene [b].to(device))\n",
    "            z_m = m_proj(morph[b].to(device))\n",
    "\n",
    "            l_infonce = infoNCE(z_g, z_m, tau)\n",
    "            l_bleep   = masked_bleep(z_g, z_m, tau, theta)\n",
    "            loss      = alpha * l_infonce + (1 - alpha) * l_bleep\n",
    "\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(params, grad_clip)\n",
    "            opt.step()\n",
    "            running += loss.item()\n",
    "\n",
    "        # diagnostics\n",
    "        zg_n, zm_n = F.normalize(z_g, dim=1), F.normalize(z_m, dim=1)\n",
    "        pos = (zg_n * zm_n).sum(1).mean().item()\n",
    "        neg = (zg_n @ zm_n.T).mean().item()\n",
    "        print(\n",
    "            f\"E{ep:03d} | loss {running/(N//batch_size):.4f} | \"\n",
    "            f\"⟨cos⁺⟩={pos:.3f} ⟨cos⁻⟩={neg:.3f} | α={alpha:.2f}\"\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "80bdf75e-59a4-4362-bb0a-df1e9654cfdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E001 | loss 6.5798 | ⟨cos⁺⟩=0.497 ⟨cos⁻⟩=0.032 | α=1.00\n",
      "E002 | loss 5.9673 | ⟨cos⁺⟩=0.529 ⟨cos⁻⟩=0.022 | α=1.00\n",
      "E003 | loss 5.8158 | ⟨cos⁺⟩=0.552 ⟨cos⁻⟩=0.021 | α=1.00\n",
      "E004 | loss 5.7244 | ⟨cos⁺⟩=0.564 ⟨cos⁻⟩=0.012 | α=1.00\n",
      "E005 | loss 5.6606 | ⟨cos⁺⟩=0.565 ⟨cos⁻⟩=0.015 | α=1.00\n",
      "E006 | loss 5.6369 | ⟨cos⁺⟩=0.569 ⟨cos⁻⟩=0.017 | α=0.98\n",
      "E007 | loss 5.6254 | ⟨cos⁺⟩=0.566 ⟨cos⁻⟩=0.011 | α=0.96\n",
      "E008 | loss 5.6209 | ⟨cos⁺⟩=0.576 ⟨cos⁻⟩=0.009 | α=0.95\n",
      "E009 | loss 5.6216 | ⟨cos⁺⟩=0.575 ⟨cos⁻⟩=0.014 | α=0.93\n",
      "E010 | loss 5.6255 | ⟨cos⁺⟩=0.583 ⟨cos⁻⟩=0.011 | α=0.91\n",
      "E011 | loss 5.6331 | ⟨cos⁺⟩=0.592 ⟨cos⁻⟩=0.015 | α=0.89\n",
      "E012 | loss 5.6424 | ⟨cos⁺⟩=0.586 ⟨cos⁻⟩=0.011 | α=0.88\n",
      "E013 | loss 5.6539 | ⟨cos⁺⟩=0.598 ⟨cos⁻⟩=0.009 | α=0.86\n",
      "E014 | loss 5.6680 | ⟨cos⁺⟩=0.576 ⟨cos⁻⟩=0.015 | α=0.84\n",
      "E015 | loss 5.6822 | ⟨cos⁺⟩=0.593 ⟨cos⁻⟩=0.012 | α=0.82\n",
      "E016 | loss 5.6975 | ⟨cos⁺⟩=0.593 ⟨cos⁻⟩=0.009 | α=0.80\n",
      "E017 | loss 5.7155 | ⟨cos⁺⟩=0.588 ⟨cos⁻⟩=0.012 | α=0.79\n",
      "E018 | loss 5.7328 | ⟨cos⁺⟩=0.596 ⟨cos⁻⟩=0.007 | α=0.77\n",
      "E019 | loss 5.7527 | ⟨cos⁺⟩=0.594 ⟨cos⁻⟩=0.009 | α=0.75\n",
      "E020 | loss 5.7729 | ⟨cos⁺⟩=0.597 ⟨cos⁻⟩=0.017 | α=0.73\n",
      "E021 | loss 5.7939 | ⟨cos⁺⟩=0.608 ⟨cos⁻⟩=0.015 | α=0.72\n",
      "E022 | loss 5.8164 | ⟨cos⁺⟩=0.599 ⟨cos⁻⟩=0.008 | α=0.70\n",
      "E023 | loss 5.8404 | ⟨cos⁺⟩=0.608 ⟨cos⁻⟩=0.005 | α=0.68\n",
      "E024 | loss 5.8697 | ⟨cos⁺⟩=0.604 ⟨cos⁻⟩=0.011 | α=0.66\n",
      "E025 | loss 5.9086 | ⟨cos⁺⟩=0.601 ⟨cos⁻⟩=0.009 | α=0.64\n",
      "E026 | loss 5.9387 | ⟨cos⁺⟩=0.590 ⟨cos⁻⟩=0.009 | α=0.63\n",
      "E027 | loss 5.9663 | ⟨cos⁺⟩=0.598 ⟨cos⁻⟩=0.009 | α=0.61\n",
      "E028 | loss 5.9822 | ⟨cos⁺⟩=0.601 ⟨cos⁻⟩=0.007 | α=0.60\n",
      "E029 | loss 5.9808 | ⟨cos⁺⟩=0.604 ⟨cos⁻⟩=0.009 | α=0.60\n",
      "E030 | loss 5.9799 | ⟨cos⁺⟩=0.595 ⟨cos⁻⟩=0.005 | α=0.60\n",
      "E031 | loss 5.9782 | ⟨cos⁺⟩=0.603 ⟨cos⁻⟩=0.007 | α=0.60\n",
      "E032 | loss 5.9763 | ⟨cos⁺⟩=0.596 ⟨cos⁻⟩=0.006 | α=0.60\n",
      "E033 | loss 5.9751 | ⟨cos⁺⟩=0.593 ⟨cos⁻⟩=0.011 | α=0.60\n",
      "E034 | loss 5.9734 | ⟨cos⁺⟩=0.610 ⟨cos⁻⟩=0.003 | α=0.60\n",
      "E035 | loss 5.9713 | ⟨cos⁺⟩=0.606 ⟨cos⁻⟩=0.006 | α=0.60\n",
      "E036 | loss 5.9711 | ⟨cos⁺⟩=0.603 ⟨cos⁻⟩=0.005 | α=0.60\n",
      "E037 | loss 5.9694 | ⟨cos⁺⟩=0.595 ⟨cos⁻⟩=0.006 | α=0.60\n",
      "E038 | loss 5.9683 | ⟨cos⁺⟩=0.598 ⟨cos⁻⟩=0.006 | α=0.60\n",
      "E039 | loss 5.9667 | ⟨cos⁺⟩=0.598 ⟨cos⁻⟩=0.007 | α=0.60\n",
      "E040 | loss 5.9651 | ⟨cos⁺⟩=0.599 ⟨cos⁻⟩=0.007 | α=0.60\n",
      "E041 | loss 5.9637 | ⟨cos⁺⟩=0.593 ⟨cos⁻⟩=0.010 | α=0.60\n",
      "E042 | loss 5.9633 | ⟨cos⁺⟩=0.589 ⟨cos⁻⟩=0.015 | α=0.60\n",
      "E043 | loss 5.9613 | ⟨cos⁺⟩=0.605 ⟨cos⁻⟩=0.010 | α=0.60\n",
      "E044 | loss 5.9604 | ⟨cos⁺⟩=0.586 ⟨cos⁻⟩=0.012 | α=0.60\n",
      "E045 | loss 5.9587 | ⟨cos⁺⟩=0.606 ⟨cos⁻⟩=0.003 | α=0.60\n",
      "E046 | loss 5.9577 | ⟨cos⁺⟩=0.594 ⟨cos⁻⟩=0.011 | α=0.60\n",
      "E047 | loss 5.9559 | ⟨cos⁺⟩=0.596 ⟨cos⁻⟩=0.014 | α=0.60\n",
      "E048 | loss 5.9550 | ⟨cos⁺⟩=0.592 ⟨cos⁻⟩=0.010 | α=0.60\n",
      "E049 | loss 5.9539 | ⟨cos⁺⟩=0.605 ⟨cos⁻⟩=0.009 | α=0.60\n",
      "E050 | loss 5.9531 | ⟨cos⁺⟩=0.596 ⟨cos⁻⟩=0.013 | α=0.60\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_bleep(gene_tensor, morph_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c651b7-2074-4e66-a56c-1feb47d9d4be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch, torch.nn.functional as F\n",
    "\n",
    "def neighbourhood_alignment(z_gene, z_morph, k=20):\n",
    "    # z_* : (N,D) tensors, L2 normalised\n",
    "    z_gene  = F.normalize(z_gene, dim=1)\n",
    "    z_morph = F.normalize(z_morph, dim=1)\n",
    "\n",
    "    nn_gene  = torch.topk(z_gene  @ z_gene .T, k+1, dim=-1).indices[:,1:]\n",
    "    nn_morph = torch.topk(z_morph @ z_morph.T, k+1, dim=-1).indices[:,1:]\n",
    "\n",
    "    overlap = (nn_gene == nn_morph).float().sum(dim=1).mean() / k\n",
    "    return overlap.item()          # fraction of shared neighbours\n",
    "\n",
    "print(\"k-NN overlap =\", neighbourhood_alignment(gene_tensor, morph_tensor))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9133cb4-c1bc-49cc-97a3-c54348289c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After training, compute final embeddings\n",
    "\n",
    "with torch.no_grad():\n",
    "    gene_emb_final = gene_proj_net(gene_tensor).cpu().numpy()\n",
    "    morph_emb_final = morph_proj_net(morph_tensor).cpu().numpy()\n",
    "\n",
    "# Combine embeddings (e.g., average)\n",
    "joint_embeddings = (gene_emb_final + morph_emb_final) / 2\n",
    "\n",
    "# Save embeddings\n",
    "gene_emb_df = pd.DataFrame(gene_emb_final, index=gene_embeddings.index)\n",
    "morph_emb_df = pd.DataFrame(morph_emb_final, index=gene_embeddings.index)\n",
    "joint_emb_df = pd.DataFrame(joint_embeddings, index=gene_embeddings.index)\n",
    "\n",
    "# os.makedirs(os.path.join(embedding_dir,\"contrastive_learning\"), exist_ok=True)\n",
    "# gene_emb_df.to_csv(os.path.join(embedding_dir,\"contrastive_learning\", f\"gene_projection_embeddings_{morph_version}.csv\"))\n",
    "# morph_emb_df.to_csv(os.path.join(embedding_dir,\"contrastive_learning\", f\"morph_projection_embeddings_{morph_version}.csv\"))\n",
    "# joint_emb_df.to_csv(os.path.join(embedding_dir,\"contrastive_learning\", f\"joint_embeddings_{morph_version}.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca089a08-68a1-4c5f-9743-77a27f873c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "edata = sc.AnnData(joint_emb_df.values, obs=pd.DataFrame(index=joint_emb_df.index))\n",
    "\n",
    "# Compute neighborhood graph (for clustering)\n",
    "sc.pp.neighbors(edata, n_neighbors=15, use_rep='X')\n",
    "\n",
    "# UMAP dimensionality reduction\n",
    "sc.tl.umap(edata)\n",
    "\n",
    "# Leiden clustering\n",
    "sc.tl.leiden(edata, resolution=0.5)\n",
    "\n",
    "# Plot UMAP with clusters\n",
    "sc.pl.umap(edata, color='leiden', size=20, legend_loc='right margin', frameon=False)\n",
    "\n",
    "# Extract Scanpy's cluster colors from UMAP plot\n",
    "leiden_palette = edata.uns[\"leiden_colors\"]\n",
    "leiden_ids = sorted(edata.obs[\"leiden\"].astype(int).unique())\n",
    "cluster_color_map = {str(i): c for i, c in zip(leiden_ids, leiden_palette)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe7422e-7c1a-42e2-be3f-220b4fcb3647",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming spatial_coords dataframe matches joint embeddings index\n",
    "edata.obs['x'] = spatial_coords.loc[edata.obs_names, 'x']\n",
    "edata.obs['y'] = spatial_coords.loc[edata.obs_names, 'y']\n",
    "\n",
    "cluster_key=\"leiden\"\n",
    "cluster_colors = edata.obs[cluster_key].astype(str).map(cluster_color_map)\n",
    "\n",
    "# Spatial cluster visualization\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(edata.obs['x'], edata.obs['y'], c=cluster_colors, s=1)\n",
    "plt.gca().invert_yaxis()  # Adjust as needed\n",
    "plt.axis('equal')\n",
    "plt.title('Spatial Visualization of Clusters')\n",
    "plt.xlabel('X Coordinate')\n",
    "plt.ylabel('Y Coordinate')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c4cb44-48ce-4783-8742-96fa789b599a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell Classificatin network\n",
    "\n",
    "class ContrastiveDataset(Dataset):\n",
    "    def __init__(self, gene_128, morph_128, labels):\n",
    "        self.gene   = torch.tensor(gene_128,  dtype=torch.float32)\n",
    "        self.morph  = torch.tensor(morph_128, dtype=torch.float32)\n",
    "        self.labels = torch.tensor(labels.values, dtype=torch.long)\n",
    "    def __len__(self): \n",
    "        return len(self.labels)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.gene[idx], self.morph[idx], self.labels[idx]\n",
    "\n",
    "\n",
    "\n",
    "class DualFeatureTransformer(nn.Module):\n",
    "    def __init__(self, d_in=128, d_model=128, heads=4, num_layers=4, n_cls=3):\n",
    "        super().__init__()\n",
    "        self.gene_proj  = nn.Linear(d_in, d_model)\n",
    "        self.morph_proj = nn.Linear(d_in, d_model)\n",
    "        self.gene_type  = nn.Parameter(torch.randn(1, d_model))\n",
    "        self.morph_type = nn.Parameter(torch.randn(1, d_model))\n",
    "        self.layers = nn.ModuleList(\n",
    "            nn.TransformerEncoderLayer(\n",
    "                d_model=d_model, nhead=heads, batch_first=True\n",
    "            ) for _ in range(num_layers)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.LayerNorm(d_model),\n",
    "            nn.Linear(d_model, n_cls)\n",
    "        )\n",
    "    def forward(self, g, m):\n",
    "        g = self.gene_proj(g)  + self.gene_type   # [B,d_model]\n",
    "        m = self.morph_proj(m) + self.morph_type\n",
    "        x = torch.stack([g, m], dim=1)            # [B,2,d_model]\n",
    "        for layer in self.layers: \n",
    "            x = layer(x)\n",
    "        return self.classifier(x.mean(1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a78b1a8-a87d-4151-bd83-315964d70bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ──────────────────────────────────────────────────────────\n",
    "# 0  Choose features depending on fusion‑decoder flag\n",
    "# ──────────────────────────────────────────────────────────\n",
    "if fusion_decoder:\n",
    "    # gene_list and morph_list were never built — let's make them explicit\n",
    "    gene_list, morph_list = [], []\n",
    "\n",
    "    fusion_dec.eval()\n",
    "    with torch.no_grad():\n",
    "        for s in range(0, N, eval_batch):\n",
    "            e = min(s + eval_batch, N)\n",
    "            g_proj = gene_proj_net(gene_tensor[s:e])       # (b,128)\n",
    "            m_proj = morph_proj_net(morph_tensor[s:e])     # (b,128)\n",
    "\n",
    "            # fused representations (one step for each direction)\n",
    "            g_dec = fusion_dec(g_proj.unsqueeze(1), m_proj.unsqueeze(1)).squeeze(1)\n",
    "            m_dec = fusion_dec(m_proj.unsqueeze(1), g_proj.unsqueeze(1)).squeeze(1)\n",
    "\n",
    "            gene_list.append(g_dec.cpu())\n",
    "            morph_list.append(m_dec.cpu())\n",
    "\n",
    "    gene_feat  = torch.cat(gene_list).numpy()   # (N,128)\n",
    "    morph_feat = torch.cat(morph_list).numpy()  # (N,128)\n",
    "\n",
    "else:\n",
    "    gene_feat  = gene_proj_net(gene_tensor).detach().cpu().numpy()\n",
    "    morph_feat = morph_proj_net(morph_tensor).detach().cpu().numpy()\n",
    "\n",
    "\n",
    "# ──────────────────────────────────────────────────────────\n",
    "# 1  Create train / val split (80 / 20)\n",
    "# ──────────────────────────────────────────────────────────\n",
    "dataset_conch = ContrastiveDataset(gene_feat, morph_feat, labels)\n",
    "split_save_dir = \"/rsrch5/home/plm/phacosta/xenium_project/Code/data_files\"\n",
    "\n",
    "with open(f\"{split_save_dir}/train_test_indices.pkl\", \"rb\") as f:\n",
    "    idx_dict = pickle.load(f)\n",
    "train_idx = np.asarray(idx_dict[\"train_idx\"])\n",
    "test_idx  = np.asarray(idx_dict[\"test_idx\"])\n",
    "\n",
    "\n",
    "train_dataset = Subset(dataset_conch, train_idx)   # ← same split\n",
    "test_dataset  = Subset(dataset_conch, test_idx)\n",
    "\n",
    "train_loader  = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader   = DataLoader(test_dataset,  batch_size=64, shuffle=False)\n",
    "\n",
    "# ──────────────────────────────────────────────────────────\n",
    "# 2  Instantiate classifier\n",
    "# ──────────────────────────────────────────────────────────\n",
    "num_classes = labels.nunique()\n",
    "clf = DualFeatureTransformer(\n",
    "    d_in=128, d_model=128, heads=4, num_layers=4, n_cls=num_classes\n",
    ").to(device)\n",
    "\n",
    "opt = torch.optim.AdamW(clf.parameters(), lr=3e-4)\n",
    "best_acc = 0.0\n",
    "\n",
    "# ──────────────────────────────────────────────────────────\n",
    "# 3  Training loop\n",
    "# ──────────────────────────────────────────────────────────\n",
    "for epoch in range(1, 21):\n",
    "    clf.train()\n",
    "    epoch_loss = 0\n",
    "    for g,m,y in train_loader:\n",
    "        g,m,y = g.to(device), m.to(device), y.to(device)\n",
    "        pred  = clf(g,m)\n",
    "        loss  = F.cross_entropy(pred, y)\n",
    "        opt.zero_grad(); loss.backward(); opt.step()\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    # ---- validation ----\n",
    "    clf.eval()\n",
    "    correct = total = 0\n",
    "    with torch.no_grad():\n",
    "        for g,m,y in test_loader:\n",
    "            g,m,y = g.to(device), m.to(device), y.to(device)\n",
    "            logits = clf(g,m)\n",
    "            correct += (logits.argmax(1) == y).sum().item()\n",
    "            total   += y.size(0)\n",
    "    acc = correct / total\n",
    "    print(f\"Epoch {epoch:02d} | loss={epoch_loss/len(train_loader):.4f} | val acc={acc:.3f}\")\n",
    "\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        # torch.save(clf.state_dict(), \"best_celltype_transformer.pth\")\n",
    "        # print(\"✓ new best model saved\")\n",
    "\n",
    "print(\"Training finished.  Best validation accuracy:\", best_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2db9883-2fcd-4039-a44a-5f8b9d654d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.eval()\n",
    "all_preds, all_labels = [], []\n",
    "with torch.no_grad():\n",
    "    for g, m, y in test_loader:\n",
    "        g, m = g.to(device), m.to(device)\n",
    "        logits = clf(g, m)\n",
    "        all_preds.append(logits.argmax(1).cpu())\n",
    "        all_labels.append(y)                 # already on CPU\n",
    "all_preds  = torch.cat(all_preds).numpy()\n",
    "all_labels = torch.cat(all_labels).numpy()\n",
    "\n",
    "\n",
    "# target_classes = (\n",
    "#     labels.cat.categories.tolist()\n",
    "#     if hasattr(labels, \"cat\")\n",
    "#     else sorted(np.unique(labels))\n",
    "# )\n",
    "# target_classes = [str(c) for c in target_classes]   # ← make them strings\n",
    "\n",
    "target_classes = [\"fibroblast\", \"endothelial\",\n",
    "                      \"t_cell\", \"b_cell\", \"macrophage\",\n",
    "                      \"epithelial\"]\n",
    "cm  = confusion_matrix(all_labels, all_preds, normalize=\"true\")\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=target_classes)\n",
    "disp.plot(cmap=\"viridis\", xticks_rotation=\"vertical\")\n",
    "plt.title(\"Confusion Matrix – Contrastive features\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(all_labels, all_preds, target_names=target_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59096434-9075-46c4-9fc3-4e3596f0b9be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phacosta (py3.10.12)",
   "language": "python",
   "name": "phacosta"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
