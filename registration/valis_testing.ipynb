{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d34e92fc-b2a9-4942-9e9e-3275a94203f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded LightGlue model\n",
      "Using local version\n",
      "Loaded LightGlue model\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "import os, sys\n",
    "\n",
    "sys.path.insert(0, \"/rsrch5/home/plm/phacosta/xenium_project/valis\")\n",
    "from valis import registration, slide_io, non_rigid_registrars\n",
    "\n",
    "from pathlib import Path\n",
    "from valis.micro_rigid_registrar import MicroRigidRegistrar # For high resolution rigid registration\n",
    "import time \n",
    "import numpy as np\n",
    "import pickle \n",
    "#%%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e64af917-c482-41eb-8f93-9ace8becaad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# root_dir = \"/rsrch9/home/plm/idso_fa1_pathology/TIER1/paul-xenium/TMP-IL-Pilot/20250515__183240__CIMAC_Validation/test_registration\"\n",
    "root_dir = \"/rsrch9/home/plm/idso_fa1_pathology/TIER1/paul-xenium/TMP-IL-Pilot/20250515__183240__CIMAC_Validation/test_registration/individual_registration/valis_registration\"\n",
    "core_name = \"A-2\"\n",
    "slide_src_dir = os.path.join(root_dir, \"cores\")\n",
    "results_dst_dir = os.path.join(root_dir, \"slide_registration_example_cores\")\n",
    "registered_slide_dst_dir = os.path.join(root_dir, \"slide_registration_example_cores/registered_slides\")\n",
    "reference_slide = f\"morphology_focus_{core_name}.ome.tif\"\n",
    "reference_slide_fullpath = os.path.join(slide_src_dir, reference_slide)\n",
    "\n",
    "img_to_register = f\"{core_name}.ome.tif\"\n",
    "img_to_register_fullpath = os.path.join(slide_src_dir, img_to_register)\n",
    "\n",
    "\n",
    "assert os.path.exists(reference_slide_fullpath)\n",
    "assert os.path.exists(img_to_register_fullpath)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "230c9a37-67cb-4f6c-a3ac-6aaf475b69b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "# # Create a Valis object and use it to register the slides in slide_src_dir, aligning *towards* the reference slide.\n",
    "# registrar = registration.Valis(slide_src_dir, results_dst_dir, reference_img_f=reference_slide)\n",
    "# reader_cls = slide_io.VipsSlideReader      # or slide_io.TifffileSlideReader\n",
    "\n",
    "# rigid_registrar, non_rigid_registrar, error_df = registrar.register()\n",
    "\n",
    "# # Perform micro-registration on higher resolution images, aligning *directly to* the reference image\n",
    "# registrar.register_micro(max_non_rigid_registration_dim_px=5000, align_to_reference=True)\n",
    "\n",
    "# # # Save all registered slides as ome.tiff\n",
    "# # registrar.warp_and_save_slides(registered_slide_dst_dir, crop=\"all\", compression=\"jpeg\", Q=90)\n",
    "\n",
    "# # # Delete the duplicated reference images\n",
    "# # (registered_slide_dst_dir/ reference_slide).unlink()\n",
    "\n",
    "# # Save non-rigid\n",
    "# registered_slide_dst_dir = Path(results_dst_dir)/\"registered_slides_affine\"\n",
    "# registrar.warp_and_save_slides(registered_slide_dst_dir, crop=\"all\", non_rigid=False, compression=\"jpeg\", Q=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe4ab12-dfcd-45c2-a9ec-a8b449ce2673",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== Converting images\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting images:   0%|          | 0/2 [00:00<?, ?image/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A-2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting images:  50%|█████     | 1/2 [01:49<01:49, 109.48s/image]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "morphology_focus_A-2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting images: 100%|██████████| 2/2 [02:12<00:00, 66.25s/image] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== Processing images\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images :   0%|          | 0/2 [00:00<?, ?image/s]/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:1416: RuntimeWarning: Explicit initial center position passed: performing only one init in KMeans instead of n_init=10.\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:1416: RuntimeWarning: Explicit initial center position passed: performing only one init in KMeans instead of n_init=10.\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:1416: RuntimeWarning: Explicit initial center position passed: performing only one init in KMeans instead of n_init=10.\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:1416: RuntimeWarning: Explicit initial center position passed: performing only one init in KMeans instead of n_init=10.\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:1416: RuntimeWarning: Explicit initial center position passed: performing only one init in KMeans instead of n_init=10.\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "Processing images : 100%|██████████| 2/2 [01:38<00:00, 49.26s/image]\n",
      "Normalizing images: 100%|██████████| 2/2 [00:00<00:00, 19.65image/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== Rigid registration\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SLF4J: No SLF4J providers were found.\n",
      "SLF4J: Defaulting to no-operation (NOP) logger implementation\n",
      "SLF4J: See https://www.slf4j.org/codes.html#noProviders for further details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JVM has been initialized. Be sure to call registration.kill_jvm() or slide_io.kill_jvm() at the end of your script.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detecting features   :   0%|          | 0/2 [00:00<?, ?image/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "detecting features in level 0 with image shape (511, 501)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detecting features   :  50%|█████     | 1/2 [00:01<00:01,  1.29s/image]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "detecting features in level 0 with image shape (512, 508)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detecting features   : 100%|██████████| 2/2 [00:02<00:00,  1.15s/image]\n",
      "QUEUEING TASKS | Matching images      : 100%|██████████| 2/2 [00:00<00:00, 1259.55image/s]\n",
      "PROCESSING TASKS | Matching images      : 100%|██████████| 2/2 [00:01<00:00,  1.80image/s]\n",
      "COLLECTING RESULTS | Matching images      : 100%|██████████| 2/2 [00:00<00:00, 52103.16image/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images sorted using VggFD features. Will now use LightGlueMatcher to match images using DiskFD features\n",
      "detecting features in level 0 with image shape (512, 508)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Re-matching images:   0%|          | 0/1 [00:00<?, ?image/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "detecting features in level 0 with image shape (1077, 1083)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Re-matching images: 100%|██████████| 1/1 [00:00<00:00,  1.71image/s]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When matching A-2 to morphology_focus_A-2, the results are better when using LightGlueMatcher using DiskFD features. Number of matches: LightGlueMatcher using DiskFD features = 6, VggFD = 5. Mean distance between matches: LightGlueMatcher using DiskFD features = 31.38, VggFD = 94.26. Will replace old matches when estimating rigid transform.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 735.97it/s]\n",
      "Finding transforms   : 100%|██████████| 1/1 [00:00<00:00, 1772.74image/s]\n",
      "Finalizing           : 100%|██████████| 2/2 [00:00<00:00, 6652.35image/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Rigid registration complete in 10.408 seconds\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:1416: RuntimeWarning: Explicit initial center position passed: performing only one init in KMeans instead of n_init=10.\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:1416: RuntimeWarning: Explicit initial center position passed: performing only one init in KMeans instead of n_init=10.\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:1416: RuntimeWarning: Explicit initial center position passed: performing only one init in KMeans instead of n_init=10.\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:1416: RuntimeWarning: Explicit initial center position passed: performing only one init in KMeans instead of n_init=10.\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:1416: RuntimeWarning: Explicit initial center position passed: performing only one init in KMeans instead of n_init=10.\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== Micro-rigid registration\n",
      "\n",
      "Aligning A-2 to morphology_focus_A-2. ROI width, height is [ 1925.55280119  1985.98499062] pixels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "QUEUEING TASKS | : 100%|██████████| 16/16 [00:00<00:00, 60.30it/s]\n",
      "PROCESSING TASKS | :   0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "\n",
    "# Perform high resolution rigid registration using the MicroRigidRegistrar\n",
    "start = time.time()\n",
    "registrar = registration.Valis(slide_src_dir, results_dst_dir, reference_img_f=reference_slide, align_to_reference=True, micro_rigid_registrar_cls=MicroRigidRegistrar)\n",
    "\n",
    "rigid_registrar, non_rigid_registrar, error_df = registrar.register()\n",
    "\n",
    "# registrar.warp_and_save_slides(os.path.join(registered_slide_dst_dir, \"standard\"), crop=\"reference\", non_rigid=True, compression=\"jpeg\", Q=85)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c542736a-035f-44d9-9a33-67f54067398f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate what `max_non_rigid_registration_dim_px` needs to be to do non-rigid registration on an image that is 25% full resolution.\n",
    "# img_dims = np.array([slide_obj.slide_dimensions_wh[0] for slide_obj in registrar.slide_dict.values()])\n",
    "# min_max_size = np.min([np.max(d) for d in img_dims])\n",
    "# img_areas = [np.multiply(*d) for d in img_dims]\n",
    "# max_img_w, max_img_h = tuple(img_dims[np.argmax(img_areas)])\n",
    "# micro_reg_size = np.floor(min_max_size*micro_reg_fraction).astype(int)\n",
    "\n",
    "\n",
    "# # Perform high resolution non-rigid registration\n",
    "# # micro_reg, micro_error = registrar.register_micro(max_non_rigid_registration_dim_px=micro_reg_size)\n",
    "# micro_reg, micro_err = registrar.register_micro(\n",
    "#     non_rigid_registrar_cls=non_rigid_registrars.SimpleElastixWarper(),\n",
    "#     max_non_rigid_registration_dim_px=micro_reg_size,   # or None for full res\n",
    "#     align_to_reference=True\n",
    "# )\n",
    "# registrar.warp_and_save_slides(registered_slide_dst_dir, crop=\"all\", non_rigid=True, compression=\"jpeg\", Q=90)\n",
    "\n",
    "\n",
    "# stop = time.time()\n",
    "# elapsed = stop - start\n",
    "# print(f\"regisration time is {elapsed/60} minutes\")\n",
    "\n",
    "# # We can also plot the high resolution matches using `Valis.draw_matches`:\n",
    "# matches_dst_dir = os.path.join(registrar.dst_dir, \"hi_rez_matches\")\n",
    "# registrar.draw_matches(matches_dst_dir)\n",
    "\n",
    "# %%\n",
    "# Kill the JVM\n",
    "# registration.kill_jvm()\n",
    "# %%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2cb083-f111-4954-a69c-e9b419e629ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calculate what `max_non_rigid_registration_dim_px` needs to be to do non-rigid registration on an image that is 25% full resolution.\n",
    "micro_reg_fraction = 0.25\n",
    "img_dims = np.array([slide_obj.slide_dimensions_wh[0] for slide_obj in registrar.slide_dict.values()])\n",
    "min_max_size = np.min([np.max(d) for d in img_dims])\n",
    "img_areas = [np.multiply(*d) for d in img_dims]\n",
    "max_img_w, max_img_h = tuple(img_dims[np.argmax(img_areas)])\n",
    "micro_reg_size = np.floor(min_max_size*micro_reg_fraction).astype(int)\n",
    "\n",
    "# Perform high resolution non-rigid registration\n",
    "micro_reg, micro_error = registrar.register_micro(max_non_rigid_registration_dim_px=micro_reg_size, align_to_reference=True)\n",
    "\n",
    "\n",
    "stop = time.time()\n",
    "elapsed = stop - start\n",
    "print(f\"regisration time is {elapsed/60} minutes\")\n",
    "\n",
    "registrar.warp_and_save_slides(os.path.join(registered_slide_dst_dir, \"micro\"), crop=\"reference\", non_rigid=True, compression=\"jpeg\", Q=85)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc31c84-07f6-43bf-979b-3e57ca472b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # 2.  Grab the two Slide objects ---------------------------------------------\n",
    "# ref_slide = registrar.get_slide(ref_f)\n",
    "# he_slide  = registrar.get_slide(he_f)\n",
    "\n",
    "# # 3A.  QUICK preview: warp a thumbnail-sized RGB array ------------------------\n",
    "# thumb = ref_slide.warp_img_from_to(\n",
    "#             img=he_slide.image,              # warp the H&E thumbnail\n",
    "#             to_slide_obj=ref_slide,          # target = reference slide\n",
    "#             dst_slide_level=ref_slide.image.shape[0:2])   # same size as ref thumb\n",
    "\n",
    "# io.imsave(os.path.join(results, \"he_warped_preview.png\"), thumb)\n",
    "\n",
    "# # 3B.  FULL-RES warp (use VIPS for big WSIs) ----------------------------------\n",
    "# he_vips  = he_slide.slide2vips(level=0)      # full-res pyramid level 0\n",
    "# warped_v = he_slide.warp_img_from_to(\n",
    "#               img=he_vips,\n",
    "#               to_slide_obj=ref_slide,\n",
    "#               dst_slide_level=0)             # keep full resolution\n",
    "\n",
    "# warped_v.tiffsave(os.path.join(results, \"he_warped_fullres.ome.tif\"),\n",
    "#                   compression=\"jpeg\", Q=90)  # adjust options as desired\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9521e80-d9e9-4a46-bf84-75414f4fbc5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tifffile as tf\n",
    "import cv2\n",
    "\n",
    "sample_name = \"Xenium H&E Meso1-ICON2 TMA 5-21-2025_matching_orientation.ome.tiff\"\n",
    "file_path = os.path.join(registered_slide_dst_dir, \"micro\", sample_name)\n",
    "# Extract tiling information and pyramid level count from original H&E image\n",
    "with tf.TiffFile(file_path) as original_tif:\n",
    "    image_data = original_tif.series[0].asarray()\n",
    "\n",
    "    print(\"OME.TIF file detected. Extracting metadata\")\n",
    "    tile_width = original_tif.pages[0].tilewidth\n",
    "    tile_height = original_tif.pages[0].tilelength\n",
    "    num_subifds = len(original_tif.pages[0].subifds)\n",
    "    print(\"Tile width:\", tile_width, \"Tile height:\", tile_height, \"Current number of levels:\", num_subifds+1)\n",
    "\n",
    "    meta = tf.xml2dict(original_tif.ome_metadata)\n",
    "\n",
    "    image_block = meta['OME']['Image']\n",
    "    if isinstance(image_block, list):\n",
    "        image_block = image_block[0]\n",
    "\n",
    "    pixels_block = image_block['Pixels']\n",
    "    res = (\n",
    "        float(pixels_block.get('PhysicalSizeX', 0)),\n",
    "        float(pixels_block.get('PhysicalSizeY', 0))\n",
    "            )       \n",
    "    px_size_x, px_size_y = res\n",
    "    print(px_size_x)\n",
    "    unit = meta['OME']['Image']['Pixels']['PhysicalSizeXUnit']\n",
    "    print(unit)\n",
    "    channel_names = []\n",
    "    try:\n",
    "        channels = meta['OME']['Image']['Pixels']['Channel']\n",
    "        \n",
    "        if isinstance(channels, list):  # multiple channels\n",
    "            for ch in channels:\n",
    "                channel_names.append(ch['Name'])\n",
    "        elif isinstance(channels, dict):  # single channel\n",
    "            channel_names.append(channels['Name'])\n",
    "    except KeyError:\n",
    "        channel_names = None \n",
    "\n",
    "metadata = {'axes': 'YXC',\n",
    "            'PhysicalSizeX': px_size_x,\n",
    "            'PhysicalSizeY': px_size_y,\n",
    "            'PhysicalSizeXUnit': unit,\n",
    "            'PhysicalSizeYUnit': unit,\n",
    "            'Channel': {'Name': None}}\n",
    "\n",
    "tile_size=(tile_width, tile_width)\n",
    "photometric_interp = \"rgb\"\n",
    "subresolutions=8\n",
    "filename = file_path.replace(\".ome.tiff\", \"_converted.ome.tif\").replace(\" \", \"_\")\n",
    "with tf.TiffWriter(filename, bigtiff=True) as tif:\n",
    "    px_size_x = metadata['PhysicalSizeX']\n",
    "    px_size_y = metadata['PhysicalSizeY']\n",
    "\n",
    "    options = dict(\n",
    "        photometric=photometric_interp,\n",
    "        tile=tile_size,\n",
    "        maxworkers=16,\n",
    "        compression=\"jpeg\",\n",
    "        compressionargs={\"level\": 85},  # Can be tuned between 75–95\n",
    "        resolutionunit='CENTIMETER',\n",
    "    )\n",
    "\n",
    "    # Write base level (level 0)\n",
    "    print(\"Writing pyramid level 0\")\n",
    "    tif.write(\n",
    "        image_data,\n",
    "        subifds=subresolutions,\n",
    "        resolution=(1e4 / px_size_x, 1e4 / px_size_y),\n",
    "        metadata=metadata,\n",
    "        **options\n",
    "    )\n",
    "\n",
    "    print(\"Warning: level_ds not provided. Falling back to halving strategy.\")\n",
    "    current = image_data.copy()\n",
    "    scale = 1\n",
    "    for i in range(subresolutions):\n",
    "        scale *= 2\n",
    "        new_w = current.shape[1] // 2\n",
    "        new_h = current.shape[0] // 2\n",
    "        current = cv2.resize(current, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "        print(f\"Writing pyramid level {i + 1} with shape {current.shape}\")\n",
    "        tif.write(\n",
    "            current,\n",
    "            subfiletype=1,\n",
    "            resolution=(1e4 / (scale * px_size_x), 1e4 / (scale * px_size_y)),\n",
    "            **options\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f3dba1-4b54-4c68-9fde-b3f13cc0fd13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phacosta (py3.10.12)",
   "language": "python",
   "name": "phacosta"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
